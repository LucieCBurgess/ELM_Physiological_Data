Last login: Fri Aug  4 09:54:21 on console
DIGI-LBurgess-6:~ lucieburgess$ ./bin/spark-shell
-bash: ./bin/spark-shell: No such file or directory
DIGI-LBurgess-6:~ lucieburgess$ cd /Applications/spark-2.2.0-bin-hadoop2.7 
DIGI-LBurgess-6:spark-2.2.0-bin-hadoop2.7 lucieburgess$ ./bin/spark-shell
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
17/08/04 10:15:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/08/04 10:15:24 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
Spark context Web UI available at http://192.168.1.163:4040
Spark context available as 'sc' (master = local[*], app id = local-1501838118262).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.2.0
      /_/
         
Using Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_112)
Type in expressions to have them evaluated.
Type :help for more information.

scala> --help
<console>:24: error: not found: value --
       --help
       ^

scala> spark-submit run-example SparkPi
<console>:24: error: value - is not a member of org.apache.spark.sql.SparkSession
       spark-submit run-example SparkPi
            ^
<console>:24: error: not found: value submit
       spark-submit run-example SparkPi
             ^
<console>:24: error: not found: value example
       spark-submit run-example SparkPi
                        ^

scala> .bin/run-example SparkPi
<console>:25: error: value bin is not a member of org.apache.spark.SparkContext
       sc.bin/run-example SparkPi
          ^
<console>:25: error: not found: value run
       sc.bin/run-example SparkPi
              ^
<console>:25: error: not found: value example
       sc.bin/run-example SparkPi
                  ^

scala> ./bin/run-example SparkPi
<console>:1: error: illegal start of definition
./bin/run-example SparkPi
^

scala> /bin/run-example SparkPi
<console>:24: error: not found: value /
       /bin/run-example SparkPi
       ^
<console>:24: error: not found: value /
       /bin/run-example SparkPi
           ^
<console>:24: error: not found: value example
       /bin/run-example SparkPi
                ^

scala> spark-shell -h
<console>:24: error: value - is not a member of org.apache.spark.sql.SparkSession
       spark-shell -h
            ^
<console>:24: error: not found: value shell
       spark-shell -h
             ^
<console>:24: error: not found: value h
       spark-shell -h
                    ^

scala> -h
<console>:24: error: not found: value h
       -h
        ^

scala> hdfs dfs -put /Users/lucieburgess/Documents/Health\ sector/5\ year\ strategic\ plan/Digital\ Catapult\ Health\ Five\ Year\ Strategic\ Plan_20.04.2017_v2.docx 
<console>:1: error: ';' expected but double literal found.
hdfs dfs -put /Users/lucieburgess/Documents/Health\ sector/5\ year\ strategic\ plan/Digital\ Catapult\ Health\ Five\ Year\ Strategic\ Plan_20.04.2017_v2.docx
                                                                                                                                             ^
<console>:1: error: Invalid literal number
hdfs dfs -put /Users/lucieburgess/Documents/Health\ sector/5\ year\ strategic\ plan/Digital\ Catapult\ Health\ Five\ Year\ Strategic\ Plan_20.04.2017_v2.docx
                                                                                                                                                ^

scala> :q
DIGI-LBurgess-6:spark-2.2.0-bin-hadoop2.7 lucieburgess$ hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt 
-bash: hdfs: command not found
DIGI-LBurgess-6:spark-2.2.0-bin-hadoop2.7 lucieburgess$ ./bin/spark-shell
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
17/08/04 10:32:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/08/04 10:32:31 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
Spark context Web UI available at http://192.168.1.163:4040
Spark context available as 'sc' (master = local[*], app id = local-1501839145895).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.2.0
      /_/
         
Using Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_112)
Type in expressions to have them evaluated.
Type :help for more information.

scala> $ hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt 
<console>:24: error: not found: value $
       $ hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt
       ^
<console>:24: error: not found: value dfs
       $ hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt
              ^
<console>:24: error: not found: value put
       $ hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt
                   ^
<console>:24: error: not found: value Users
       $ hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt
                        ^
<console>:24: error: not found: value lucieburgess
       $ hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt
                              ^
<console>:24: error: not found: value Desktop
       $ hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt
                                           ^
<console>:24: error: not found: value Spark_test_text_file
       $ hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt
                                                   ^

scala> hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt 
<console>:24: error: not found: value hdfs
       hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt
       ^
<console>:24: error: not found: value put
       hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt
                 ^
<console>:24: error: not found: value Users
       hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt
                      ^
<console>:24: error: not found: value lucieburgess
       hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt
                            ^
<console>:24: error: not found: value Desktop
       hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt
                                         ^
<console>:24: error: not found: value Spark_test_text_file
       hdfs dfs -put /Users/lucieburgess/Desktop/Spark_test_text_file.txt
                                                 ^

scala> hdfs dfs -put "/Users/lucieburgess/Desktop/Spark_test_text_file.txt" 
<console>:1: error: ';' expected but string literal found.
hdfs dfs -put "/Users/lucieburgess/Desktop/Spark_test_text_file.txt"
              ^

scala> hdfs dfs -put input
<console>:24: error: not found: value hdfs
       hdfs dfs -put input
       ^
<console>:24: error: not found: value put
       hdfs dfs -put input
                 ^

scala> sc.version
res3: String = 2.2.0

scala> spark.version
res4: String = 2.2.0

scala> :imports
 1) import spark.implicits._       (64 terms, 34 are implicit)
 2) import spark.sql               (1 terms)

scala> :type spark
org.apache.spark.sql.SparkSession

scala> :type sc
org.apache.spark.SparkContext

scala> spark-submit run-example LocalPi
<console>:24: error: value - is not a member of org.apache.spark.sql.SparkSession
       spark-submit run-example LocalPi
            ^
<console>:24: error: not found: value submit
       spark-submit run-example LocalPi
             ^
<console>:24: error: not found: value example
       spark-submit run-example LocalPi
                        ^

scala> spark-submit run-example "LocalPi"
<console>:1: error: ';' expected but string literal found.
spark-submit run-example "LocalPi"
                         ^

scala> exec spark-submit run-example "LocalPi"
<console>:1: error: ';' expected but string literal found.
exec spark-submit run-example "LocalPi"
                              ^

scala> ./bin/run-example SparkPi
<console>:1: error: illegal start of definition
./bin/run-example SparkPi
^

scala> run-example SparkPi
<console>:24: error: not found: value run
       run-example SparkPi
       ^
<console>:24: error: not found: value example
       run-example SparkPi
           ^

scala> spark-submit "LocalPi"
<console>:1: error: ';' expected but string literal found.
spark-submit "LocalPi"
             ^

scala> 
